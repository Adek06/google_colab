{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_steps_with_tensor_flow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ajVM7rkoYXeL",
        "ci1ISxxrZ7v0",
        "copyright-notice"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adek06/google_colab/blob/master/first_steps_with_tensor_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copyright-notice",
        "colab_type": "text"
      },
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "copyright-notice2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3CKqFUqL2-",
        "colab_type": "text"
      },
      "source": [
        " # 使用 TensorFlow 的基本步骤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd2Zkk1LE2Zr",
        "colab_type": "text"
      },
      "source": [
        " **学习目标：**\n",
        "  * 学习基本的 TensorFlow 概念\n",
        "  * 在 TensorFlow 中使用 `LinearRegressor` 类并基于单个输入特征预测各城市街区的房屋价值中位数\n",
        "  * 使用均方根误差 (RMSE) 评估模型预测的准确率\n",
        "  * 通过调整模型的超参数提高模型准确率"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxiIKhP4E2Zr",
        "colab_type": "text"
      },
      "source": [
        " 数据基于加利福尼亚州 1990 年的人口普查数据。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TjLjL9IU80G",
        "colab_type": "text"
      },
      "source": [
        " ## 设置\n",
        "在此第一个单元格中，我们将加载必要的库。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVFf5asKE2Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipRyUHjhU80Q",
        "colab_type": "text"
      },
      "source": [
        " 接下来，我们将加载数据集。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ivCDWnwE2Zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "418eeb0e-b36e-4099-c56e-ab3d4dae739b"
      },
      "source": [
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
        "california_housing_dataframe"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>34.2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.5</td>\n",
              "      <td>34.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.6</td>\n",
              "      <td>33.6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16995</th>\n",
              "      <td>-124.3</td>\n",
              "      <td>40.6</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2217.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>111400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16996</th>\n",
              "      <td>-124.3</td>\n",
              "      <td>40.7</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2349.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>79000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16997</th>\n",
              "      <td>-124.3</td>\n",
              "      <td>41.8</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2677.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>1244.0</td>\n",
              "      <td>456.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>103600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16998</th>\n",
              "      <td>-124.3</td>\n",
              "      <td>41.8</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2672.0</td>\n",
              "      <td>552.0</td>\n",
              "      <td>1298.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>85800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16999</th>\n",
              "      <td>-124.3</td>\n",
              "      <td>40.5</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1820.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>94600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0         -114.3      34.2                15.0       5612.0          1283.0   \n",
              "1         -114.5      34.4                19.0       7650.0          1901.0   \n",
              "2         -114.6      33.7                17.0        720.0           174.0   \n",
              "3         -114.6      33.6                14.0       1501.0           337.0   \n",
              "4         -114.6      33.6                20.0       1454.0           326.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "16995     -124.3      40.6                52.0       2217.0           394.0   \n",
              "16996     -124.3      40.7                36.0       2349.0           528.0   \n",
              "16997     -124.3      41.8                17.0       2677.0           531.0   \n",
              "16998     -124.3      41.8                19.0       2672.0           552.0   \n",
              "16999     -124.3      40.5                52.0       1820.0           300.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "0          1015.0       472.0            1.5             66900.0  \n",
              "1          1129.0       463.0            1.8             80100.0  \n",
              "2           333.0       117.0            1.7             85700.0  \n",
              "3           515.0       226.0            3.2             73400.0  \n",
              "4           624.0       262.0            1.9             65500.0  \n",
              "...           ...         ...            ...                 ...  \n",
              "16995       907.0       369.0            2.4            111400.0  \n",
              "16996      1194.0       465.0            2.5             79000.0  \n",
              "16997      1244.0       456.0            3.0            103600.0  \n",
              "16998      1298.0       478.0            2.0             85800.0  \n",
              "16999       806.0       270.0            3.0             94600.0  \n",
              "\n",
              "[17000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVk_qlG6U80j",
        "colab_type": "text"
      },
      "source": [
        " 我们将对数据进行随机化处理，以确保不会出现任何病态排序结果（可能会损害随机梯度下降法的效果）。此外，我们会将 `median_house_value` 调整为以千为单位，这样，模型就能够以常用范围内的学习速率较为轻松地学习这些数据。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0eVyguIU80m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "be644952-223a-43ea-a578-5ce7b85a78ad"
      },
      "source": [
        "california_housing_dataframe = california_housing_dataframe.reindex(\n",
        "    np.random.permutation(california_housing_dataframe.index))\n",
        "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
        "california_housing_dataframe"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12824</th>\n",
              "      <td>-121.8</td>\n",
              "      <td>37.3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3244.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>1769.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>224.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2956</th>\n",
              "      <td>-117.8</td>\n",
              "      <td>33.5</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2024.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>617.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>499.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3141</th>\n",
              "      <td>-117.8</td>\n",
              "      <td>33.8</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3550.0</td>\n",
              "      <td>895.0</td>\n",
              "      <td>2828.0</td>\n",
              "      <td>834.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>225.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15694</th>\n",
              "      <td>-122.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>212.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5754</th>\n",
              "      <td>-118.2</td>\n",
              "      <td>34.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>380.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>189.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3729</th>\n",
              "      <td>-117.9</td>\n",
              "      <td>33.9</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1221.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>1822.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>162.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14502</th>\n",
              "      <td>-122.1</td>\n",
              "      <td>37.5</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1210.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>981.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>148.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14809</th>\n",
              "      <td>-122.2</td>\n",
              "      <td>37.8</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2375.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>813.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>331.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5439</th>\n",
              "      <td>-118.2</td>\n",
              "      <td>34.1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>2231.0</td>\n",
              "      <td>489.0</td>\n",
              "      <td>940.0</td>\n",
              "      <td>484.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>435.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>-117.4</td>\n",
              "      <td>34.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>2228.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>1697.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>83.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "12824     -121.8      37.3                20.0       3244.0           520.0   \n",
              "2956      -117.8      33.5                28.0       2024.0           297.0   \n",
              "3141      -117.8      33.8                24.0       3550.0           895.0   \n",
              "15694     -122.4      38.0                33.0         44.0             6.0   \n",
              "5754      -118.2      34.0                33.0        151.0            83.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "3729      -117.9      33.9                29.0       1221.0           371.0   \n",
              "14502     -122.1      37.5                36.0       1210.0           236.0   \n",
              "14809     -122.2      37.8                52.0       2375.0           333.0   \n",
              "5439      -118.2      34.1                38.0       2231.0           489.0   \n",
              "2249      -117.4      34.0                38.0       2228.0           571.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "12824      1769.0       469.0            5.9               224.0  \n",
              "2956        617.0       274.0            6.8               499.1  \n",
              "3141       2828.0       834.0            2.8               225.6  \n",
              "15694        23.0        11.0            4.1               212.5  \n",
              "5754        380.0        83.0            1.4               189.6  \n",
              "...           ...         ...            ...                 ...  \n",
              "3729       1822.0       326.0            1.8               162.5  \n",
              "14502       981.0       239.0            4.0               148.9  \n",
              "14809       813.0       350.0            7.1               331.4  \n",
              "5439        940.0       484.0            5.4               435.1  \n",
              "2249       1697.0       530.0            1.9                83.4  \n",
              "\n",
              "[17000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzzlSs3PtTmt",
        "colab_type": "text"
      },
      "source": [
        " ## 检查数据\n",
        "\n",
        "建议您在使用数据之前，先对它有一个初步的了解。\n",
        "\n",
        "我们会输出关于各列的一些实用统计信息快速摘要：样本数、均值、标准偏差、最大值、最小值和各种分位数。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzb10yoVrydW",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "52394036-0d10-4326-d07d-17f89114fc4f"
      },
      "source": [
        "california_housing_dataframe.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.6</td>\n",
              "      <td>35.6</td>\n",
              "      <td>28.6</td>\n",
              "      <td>2643.7</td>\n",
              "      <td>539.4</td>\n",
              "      <td>1429.6</td>\n",
              "      <td>501.2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>207.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2179.9</td>\n",
              "      <td>421.5</td>\n",
              "      <td>1147.9</td>\n",
              "      <td>384.5</td>\n",
              "      <td>1.9</td>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.3</td>\n",
              "      <td>32.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.8</td>\n",
              "      <td>33.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1462.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>119.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.5</td>\n",
              "      <td>34.2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>180.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.0</td>\n",
              "      <td>37.7</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3151.2</td>\n",
              "      <td>648.2</td>\n",
              "      <td>1721.0</td>\n",
              "      <td>605.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>265.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.3</td>\n",
              "      <td>42.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>37937.0</td>\n",
              "      <td>6445.0</td>\n",
              "      <td>35682.0</td>\n",
              "      <td>6082.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
              "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
              "std          2.0       2.1                12.6       2179.9           421.5   \n",
              "min       -124.3      32.5                 1.0          2.0             1.0   \n",
              "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
              "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
              "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
              "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "count     17000.0     17000.0        17000.0             17000.0  \n",
              "mean       1429.6       501.2            3.9               207.3  \n",
              "std        1147.9       384.5            1.9               116.0  \n",
              "min           3.0         1.0            0.5                15.0  \n",
              "25%         790.0       282.0            2.6               119.4  \n",
              "50%        1167.0       409.0            3.5               180.4  \n",
              "75%        1721.0       605.2            4.8               265.0  \n",
              "max       35682.0      6082.0           15.0               500.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr6wYl2bt2Ep",
        "colab_type": "text"
      },
      "source": [
        " ## 构建第一个模型\n",
        "\n",
        "在本练习中，我们将尝试预测 `median_house_value`，它将是我们的标签（有时也称为目标）。我们将使用 `total_rooms` 作为输入特征。\n",
        "\n",
        "**注意**：我们使用的是城市街区级别的数据，因此该特征表示相应街区的房间总数。\n",
        "\n",
        "为了训练模型，我们将使用 TensorFlow [Estimator](https://www.tensorflow.org/get_started/estimator) API 提供的 [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) 接口。此 API 负责处理大量低级别模型搭建工作，并会提供执行模型训练、评估和推理的便利方法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cpcsieFhsNI",
        "colab_type": "text"
      },
      "source": [
        " ### 第 1 步：定义特征并配置特征列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL8-9d4ZJNR7",
        "colab_type": "text"
      },
      "source": [
        " 为了将我们的训练数据导入 TensorFlow，我们需要指定每个特征包含的数据类型。在本练习及今后的练习中，我们主要会使用以下两类数据：\n",
        "\n",
        "* **分类数据**：一种文字数据。在本练习中，我们的住房数据集不包含任何分类特征，但您可能会看到的示例包括家居风格以及房地产广告词。\n",
        "\n",
        "* **数值数据**：一种数字（整数或浮点数）数据以及您希望视为数字的数据。有时您可能会希望将数值数据（例如邮政编码）视为分类数据（我们将在稍后的部分对此进行详细说明）。\n",
        "\n",
        "在 TensorFlow 中，我们使用一种称为“**特征列**”的结构来表示特征的数据类型。特征列仅存储对特征数据的描述；不包含特征数据本身。\n",
        "\n",
        "一开始，我们只使用一个数值输入特征 `total_rooms`。以下代码会从 `california_housing_dataframe` 中提取 `total_rooms` 数据，并使用 `numeric_column` 定义特征列，这样会将其数据指定为数值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhEbFCZ86cDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1be7093a-192d-4400-a87c-a18224fa5536"
      },
      "source": [
        "# Define the input feature: total_rooms.\n",
        "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
        "\n",
        "# Configure a numeric feature column for total_rooms.\n",
        "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\")]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='total_rooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_3S8teX7Rd2",
        "colab_type": "text"
      },
      "source": [
        " **注意**：`total_rooms` 数据的形状是一维数组（每个街区的房间总数列表）。这是 `numeric_column` 的默认形状，因此我们不必将其作为参数传递。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMl3qrU5MGV6",
        "colab_type": "text"
      },
      "source": [
        " ### 第 2 步：定义目标"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw4nrfcB7kyk",
        "colab_type": "text"
      },
      "source": [
        " 接下来，我们将定义目标，也就是 `median_house_value`。同样，我们可以从 `california_housing_dataframe` 中提取它："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1NvvNkH8Kbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the label.\n",
        "targets = california_housing_dataframe[\"median_house_value\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M-rTFHL2UkA",
        "colab_type": "text"
      },
      "source": [
        " ### 第 3 步：配置 LinearRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfGQUNp7jdL",
        "colab_type": "text"
      },
      "source": [
        " 接下来，我们将使用 LinearRegressor 配置线性回归模型，并使用 `GradientDescentOptimizer`（它会实现小批量随机梯度下降法 (SGD)）训练该模型。`learning_rate` 参数可控制梯度步长的大小。\n",
        "\n",
        "**注意**：为了安全起见，我们还会通过 `clip_gradients_by_norm` 将[梯度裁剪](https://developers.google.com/machine-learning/glossary/#gradient_clipping)应用到我们的优化器。梯度裁剪可确保梯度大小在训练期间不会变得过大，梯度过大会导致梯度下降法失败。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubhtW-NGU802",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use gradient descent as the optimizer for training the model.\n",
        "my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
        "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "\n",
        "# Configure the linear regression model with our feature columns and optimizer.\n",
        "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
        "linear_regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=feature_columns,\n",
        "    optimizer=my_optimizer\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0IztwdK2f3F",
        "colab_type": "text"
      },
      "source": [
        " ### 第 4 步：定义输入函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5M5j6xSCHxx",
        "colab_type": "text"
      },
      "source": [
        " 要将加利福尼亚州住房数据导入 `LinearRegressor`，我们需要定义一个输入函数，让它告诉 TensorFlow 如何对数据进行预处理，以及在模型训练期间如何批处理、随机处理和重复数据。\n",
        "\n",
        "首先，我们将 *Pandas* 特征数据转换成 NumPy 数组字典。然后，我们可以使用 TensorFlow [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) 根据我们的数据构建 Dataset 对象，并将数据拆分成大小为 `batch_size` 的多批数据，以按照指定周期数 (num_epochs) 进行重复。\n",
        "\n",
        "**注意**：如果将默认值 `num_epochs=None` 传递到 `repeat()`，输入数据会无限期重复。\n",
        "\n",
        "然后，如果 `shuffle` 设置为 `True`，则我们会对数据进行随机处理，以便数据在训练期间以随机方式传递到模型。`buffer_size` 参数会指定 `shuffle` 将从中随机抽样的数据集的大小。\n",
        "\n",
        "最后，输入函数会为该数据集构建一个迭代器，并向 LinearRegressor 返回下一批数据。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZ9zNcHJtwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a linear regression model of one feature.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "  \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}\n",
        "    print(feature_columns)\n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwa6UeA1V5F_",
        "colab_type": "text"
      },
      "source": [
        " **注意**：在后面的练习中，我们会继续使用此输入函数。有关输入函数和 `Dataset` API 的更详细的文档，请参阅 [TensorFlow 编程人员指南](https://www.tensorflow.org/programmers_guide/datasets)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YS50CQb2ooO",
        "colab_type": "text"
      },
      "source": [
        " ### 第 5 步：训练模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP92XkzhU803",
        "colab_type": "text"
      },
      "source": [
        " 现在，我们可以在 `linear_regressor` 上调用 `train()` 来训练模型。我们会将 `my_input_fn` 封装在 `lambda` 中，以便可以将 `my_feature` 和 `target` 作为参数传入（有关详情，请参阅此 [TensorFlow 输入函数教程](https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model)），首先，我们会训练 100 步。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M-Kt6w8U803",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "96e26c1a-65b4-40a1-f637-5820558ee611"
      },
      "source": [
        "_ = linear_regressor.train(\n",
        "    input_fn = lambda:my_input_fn(my_feature, targets),\n",
        "    steps=100\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nwxqxlx2sOv",
        "colab_type": "text"
      },
      "source": [
        " ### 第 6 步：评估模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoDaF2dlJQG5",
        "colab_type": "text"
      },
      "source": [
        " 我们基于该训练数据做一次预测，看看我们的模型在训练期间与这些数据的拟合情况。\n",
        "\n",
        "**注意**：训练误差可以衡量您的模型与训练数据的拟合情况，但并**_不能_**衡量模型**_泛化到新数据_**的效果。在后面的练习中，您将探索如何拆分数据以评估模型的泛化能力。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDIxp6vcU809",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "73b1cd55-2800-42ef-88c1-cafc364053f6"
      },
      "source": [
        "# Create an input function for predictions.\n",
        "# Note: Since we're making just one prediction for each example, we don't \n",
        "# need to repeat or shuffle the data here.\n",
        "prediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n",
        "\n",
        "# Call predict() on the linear_regressor to make predictions.\n",
        "predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
        "\n",
        "# Format predictions as a NumPy array, so we can calculate error metrics.\n",
        "\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "# Print Mean Squared Error and Root Mean Squared Error.\n",
        "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
        "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
        "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
        "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "Mean Squared Error (on training data): 56367.025\n",
            "Root Mean Squared Error (on training data): 237.417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKWstXXPzOVz",
        "colab_type": "text"
      },
      "source": [
        " 这是出色的模型吗？您如何判断误差有多大？\n",
        "\n",
        "由于均方误差 (MSE) 很难解读，因此我们经常查看的是均方根误差 (RMSE)。RMSE 的一个很好的特性是，它可以在与原目标相同的规模下解读。\n",
        "\n",
        "我们来比较一下 RMSE 与目标最大值和最小值的差值："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UwqGbbxP53O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "51561d3c-c59e-4242-9217-8ebed53b53d5"
      },
      "source": [
        "min_house_value = california_housing_dataframe[\"median_house_value\"].min()\n",
        "max_house_value = california_housing_dataframe[\"median_house_value\"].max()\n",
        "min_max_difference = max_house_value - min_house_value\n",
        "\n",
        "print(\"Min. Median House Value: %0.3f\" % min_house_value)\n",
        "print(\"Max. Median House Value: %0.3f\" % max_house_value)\n",
        "print(\"Difference between Min. and Max.: %0.3f\" % min_max_difference)\n",
        "print(\"Root Mean Squared Error: %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min. Median House Value: 14.999\n",
            "Max. Median House Value: 500.001\n",
            "Difference between Min. and Max.: 485.002\n",
            "Root Mean Squared Error: 237.417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JigJr0C7Pzit",
        "colab_type": "text"
      },
      "source": [
        " 我们的误差跨越目标值的近一半范围，可以进一步缩小误差吗？\n",
        "\n",
        "这是每个模型开发者都会烦恼的问题。我们来制定一些基本策略，以降低模型误差。\n",
        "\n",
        "首先，我们可以了解一下根据总体摘要统计信息，预测和目标的符合情况。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "941nclxbzqGH",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "efe94969-d791-4b46-feb6-23fc9d8312a8"
      },
      "source": [
        "calibration_data = pd.DataFrame()\n",
        "calibration_data[\"predictions\"] = pd.Series(predictions)\n",
        "calibration_data[\"targets\"] = pd.Series(targets)\n",
        "calibration_data.describe()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.0</td>\n",
              "      <td>17000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.1</td>\n",
              "      <td>207.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.1</td>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.1</td>\n",
              "      <td>119.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.1</td>\n",
              "      <td>180.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.2</td>\n",
              "      <td>265.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.9</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       predictions  targets\n",
              "count      17000.0  17000.0\n",
              "mean           0.1    207.3\n",
              "std            0.1    116.0\n",
              "min            0.0     15.0\n",
              "25%            0.1    119.4\n",
              "50%            0.1    180.4\n",
              "75%            0.2    265.0\n",
              "max            1.9    500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2-bf8Hq36y8",
        "colab_type": "text"
      },
      "source": [
        " 好的，此信息也许有帮助。平均值与模型的 RMSE 相比情况如何？各种分位数呢？\n",
        "\n",
        "我们还可以将数据和学到的线可视化。我们已经知道，单个特征的线性回归可绘制成一条将输入 *x* 映射到输出 *y* 的线。\n",
        "\n",
        "首先，我们将获得均匀分布的随机数据样本，以便绘制可辨的散点图。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGRIi3mAU81H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = california_housing_dataframe.sample(n=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-JwuJBKU81J",
        "colab_type": "text"
      },
      "source": [
        " 然后，我们根据模型的偏差项和特征权重绘制学到的线，并绘制散点图。该线会以红色显示。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G12E76-339G",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "972d4a22-7f46-4ea8-f4ee-20c90b060da7"
      },
      "source": [
        "# Get the min and max total_rooms values.\n",
        "x_0 = sample[\"total_rooms\"].min()\n",
        "x_1 = sample[\"total_rooms\"].max()\n",
        "\n",
        "# Retrieve the final weight and bias generated during training.\n",
        "weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
        "bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
        "\n",
        "# Get the predicted median_house_values for the min and max total_rooms values.\n",
        "y_0 = weight * x_0 + bias \n",
        "y_1 = weight * x_1 + bias\n",
        "\n",
        "# Plot our regression line from (x_0, y_0) to (x_1, y_1).\n",
        "plt.plot([x_0, x_1], [y_0, y_1], c='r')\n",
        "\n",
        "# Label the graph axes.\n",
        "plt.ylabel(\"median_house_value\")\n",
        "plt.xlabel(\"total_rooms\")\n",
        "\n",
        "# Plot a scatter plot from our data sample.\n",
        "plt.scatter(sample[\"total_rooms\"], sample[\"median_house_value\"])\n",
        "\n",
        "# Display graph.\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAELCAYAAAAspXpuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJztnX2cXHV56L/PLgNsELJBc7mwkCZS\nCpXGJLBC2lg/EiqgCKy8U1B8ueXaUq9wNbpc/UDwwy3RaKm1Vi++XKEghBddQ0MbqKD2pia6YRND\nlBSESFgRImSjkk3YbJ77xzlnc3b2/M6cM3POzJmZ5/v57GdnfnNenpnZ/T2/3/MqqophGIZhRNHR\naAEMwzCM4mJKwjAMw3BiSsIwDMNwYkrCMAzDcGJKwjAMw3BiSsIwDMNwYkrCMAzDcGJKwjAMw3Bi\nSsIwDMNwckCjBaiV173udTp79uxGi2EYhtFUrF+//teqOrPScU2vJGbPns3g4GCjxTAMw2gqROQX\nSY4zc5NhGIbhxJSEYRiG4cSUhGEYhuHElIRhGIbhxJSEYRiG4ST36CYR2Qr8FhgH9qpqr4gcDqwA\nZgNbgYtVdYeICPB54B3ALuC9qvpY3jJmzScHNnHXum2Mq9IpwmWnHsNNfXMnXh8YGmb56i0Mj4zS\nKcK4Kt1dJURgZNcYR3V3seTM4+lb0BN7n+A6vxwZpXtaiT1j4+wa2zfx+oxpJc5+45E8+sR2fjky\nynT/Hjt2jU3cd8a0EqqwczT6vuF7JJUri3NrpZH3NoxWQvLuTOcriV5V/XVo7DPAy6q6TET6gRmq\n+nEReQfwITwlcSrweVU9Ne76vb29WqQQ2E8ObOKOtc9OGb9i4Sxu6pvLwNAw131rE6Nj47HX6Sp1\ncvP5c50TW9LrpCV836h7VJIrTr6k59ZKI+9tGM2CiKxX1d5KxzXK3HQecJv/+DagLzR+u3qsBbpF\n5MhGCFgtd63bFju+fPWWRBP76Ng4y1dvcb6e9DppCd836h6V5IqTL+m5tdLIextGq1EPJaHAQyKy\nXkSu8seOUNXn/ce/Ao7wH/cA4Vn2OX9sEiJylYgMisjg9u3b85K7KsYdO7Ng/Jcjo4mvFXdsmuuk\nJbi26x5J7l3LubXSyHsbRqtRDyXxZlU9CXg7cLWIvCX8onr2rlQ2L1W9VVV7VbV35syKWeV1pVMk\ndvyo7q7E14o7Ns110hJc23WPJPeu5dxaaeS9DaPVyF1JqOqw//tF4NvAKcALgRnJ//2if/gwcEzo\n9KP9scIyMDTMomWPMKd/FYuWPcLC18+IPO6yU723teTM4+kqdVa8blepkyVnHu98Pel10hK+b9Q9\nKskVJ1/Sc2ulkfc2jFYjVyUhIoeIyKHBY+AM4HFgJXClf9iVwHf8xyuB94jHQmBnyCxVOAIH6fDI\nKAoMj4zy2LM7WXTs4RM7h06RCac1QN+CHm4+fy49/qo2OK67q8SMaSUE6OnuquhkDV9H8CKZppUm\nf50zppW4YuGsiWOCe4TvO2NayYusirhv+T2SyOWSL825tdLIextGq5FrdJOIvB5v9wBeuO03VfV/\ni8hrgXuAWcAv8EJgX/ZDYP8BOAsvBPZ9qhobutTI6KZFyx5hOMLO3dPdxZr+xQ2QyDAMIxlJo5ty\nzZNQ1aeBeRHjLwGnR4wrcHWeMmWJOUgNw2h1mr5UeCM5qrsrcidhDtJiY4l2hpEcK8tRA+YgbT6i\n/EjXfWsTA0OFjo8wjIZhSqIGzEHafFiinWGkw8xNNdK3oMeUQhNhfiTDSIftJIy2whLtDCMdpiSM\ntsL8SIaRDjM3GW1FYBq06CbDSIYpiZyxcMviYX4kw0iOKYkcKe9rEIRbAjZJGYbRFJhPIkcs3NIw\njGbHlESOWLilYRjNjimJHHGFVSpecUDL8jUMo+iYksiRuJ4PVg7CMIxmwJREjpT3jijH/BOGYRQd\nUxI507eghzX9i4luaurtKMz0ZBhGUTElUSfiyj6Y6ckwjKJiSqJOVOpJbaYnwzCKiCXT+eSdGR0u\nBxHVqAgaExprGeGGYcRhOwnq14gm8E+4HNn1rkRqDXgMw6iEKQnqnxld70qkA0PDLFr2CHP6V01y\nkltGuGEYlTBzE/XPjK5nJdK4+lGWEW4YRiVMSeCZeaL8BHmaf+pViTRut9CI920YRnNh5iayN/+4\nzDuNIG63YA14DMOohO0kyNb8U2158LyijOJ2C9aAxzCMSoiqNlqGmujt7dXBwcFGizHBomWPRE7K\nPd1drOlfHHlOuWIBb0V/8/lza56w87y2YRjNi4isV9XeSseZuSljqnEG5xllFK4fJXjKyhSEYRhJ\nMXNTxlTjDM47yijsJA/MWteu2GDmJcMwKmI7iYypxhnsUiBJoozSOMktec4wjLSYksiYasw71UYZ\npZ30LXnOMIy0mLkpB9LmQFQbZeSa9G98YHPkuZY8ZxhGWuqiJESkExgEhlX1nSIyB7gbeC2wHni3\nqr4qIgcBtwMnAy8Bl6jq1nrI2GiqSa5zTe47do0xMDQ85XqWPGcYRlrqZW76MPCz0PNPA7eo6u8D\nO4AP+OMfAHb447f4x7UUWSbaxU3uUSYkS54zDCMtuSsJETkaOBv4qv9cgMXAff4htwF9/uPz/Of4\nr5/uH98SZO04jpvco3YZFg5rGEZa6mFu+jvgY8Ch/vPXAiOqutd//hwQzFI9wDYAVd0rIjv9439d\nBzlzJ85xXM1E3begh6UrNzMyOjblNdcuo141owzDaA1y3UmIyDuBF1V1fcbXvUpEBkVkcPv27Vle\nOlfycBwvPffEmkxIRaozZRhG8cjb3LQIOFdEtuI5qhcDnwe6RSTYxRwNBDPTMHAMgP/6dDwH9iRU\n9VZV7VXV3pkzZ+b7DjKklnwIF7WYkCxvwjCMSuRqblLV64DrAETkrcBHVfVyEbkXuBBPcVwJfMc/\nZaX//If+649osxeXCrHkzOMj6yjV6jiu1oSUtfnLMIzWo1F5Eh8H7haRm4Ah4Gv++NeAfxKRp4CX\ngUsbJF8upMmHqEfvacubMAyjEnVTEqr6PeB7/uOngVMijtkNXFQvmRpBklV/teXG09LOeRP1UMKG\n0QpYWY4CUq/yGe2aN2G+GMNIjimJAlIvM1DY6Q3QKTKhjFp5wrQaVoaRHFMSBSSPKCgXfQt6JnYU\n436MQKuvrM0XYxjJMSVRQOptBmq3lXU9lbBhNDuplISIvFlE3uc/nukX6jMypt7lM9ptZd2uvhjD\nqIbE0U0icgPQCxwP/F+gBNyBlzBnZEw9y2e0W5RTtaXZDaMdSRMC+y5gAfAYgKr+UkQOjT/FaAby\nSvIrMlbDyjCSkUZJvKqqKiIKICKH5CSTQX3j+G1lbRiGizRK4h4R+T94dZf+Ang/8JV8xGpv6pVM\nF8ZW1oZhRJHYca2qn8Xr8XA/nl/ielX9Ql6CtTPtFm1kGEZxSVWWQ1UfBh7OSRbDp92ijQzDKC5p\nopt+CwQVWQ/Ei256RVUPy0OwVqaSv6Hdoo0MwyguiZWEqk5EMvktRc8DFuYhVCszMDTMkvs2Mja+\nP7t5yX0bgf3+hqTRRlakzjCMvJFa2jWIyJCqLshQntT09vbq4OBgI0UAkk/YCz71EDt2TW03OmNa\niaHrz0h8vXLndvg6N5xzoikLwzBiEZH1qtpb6bg05qbzQ0878BLrdlchW8uRJhopSkFEjVeKNopy\nbgfXyTsSyjCM9iGN4/qc0OO9wFY8k1Pb04gOb3FO7GrvXa35Ku15ZiYzjOYhjU/ifXkK0sykiUbq\n7ioxMjp1N9HdVUp0r2CCrWQkTBsJVW1uRtrzGpEDYhhG9VRUEiLyBXDPSar6PzKVqAlJE430znlH\ncsfaZyPHK+HyQ7hkSkO1u6G051lfbcNoLpIk0w0C62N+2p6oqqIAr+zZO6Unw6NPbI+8hms8jMsP\nUU41dZeqzc1Ie57lgBhGc1FxJ6Gqt9VDkGYmWAHf+MDmSQ7okdExltw7Oby1lkky7pie7q6abPzV\n5makPc9yQAyjuUhclsPvH/FZEXlQRB4JfvIUrogMDA2zaNkjzOlfxaJlj0zsFPoW9BAVTTy2T1m6\ncvPE87jJ03XtgOkOv0V3V4k1/Yt5ZtnZrOlfXJXZptoeC2nPs14OhtFcpIluuhNYAZwNfBC4Eqhs\nI2khKjldoxzSwKRxV6LcaSfMrOjQFYmWyzVeLntcRFG1lWDTnmcVZw2juUijJF6rql8TkQ+r6veB\n74vIj/MSrIhk4XR1TZJJrj3iyLFwjQckjSiqthJs2vOs4qxhNA9plEQwEz0vImcDvwQOz16k4lLJ\nnzBjWsmZTR0mapK8dsUG57Urhb1Wsuc3Y0SR5VIYRjFI0+P6JhGZDnwE+CjwVeDaXKQqKHH+BIAb\nzjmRUudk20+pU7jhnBOrvnb3tBLXfWtTpLMXktnzmy2iKNj5DI+Mouzf+ZT7aAzDyJ80SmKdqu5U\n1cdV9TRVPVlVV+YmWQGp5HTtW9DD8gvn0dPdheBFHC2/cF6iFbDr2qo4w157uru4+fy5Fa9fSbkV\nDeunYRjFIY25aY2IbMVzXn9LVXfkI1JxSeJ0rcWuH3VtlxlKgDX9ixNdu9l6WDfbzscwWpk0ZTn+\nQEROAS4FPiEiPwXuVtU7cpOugOTpdI269vLVW2rOK2i2iCLLpTCM4pC2M92PgB+JyN8AfwvcBrSV\nkqg3We0CohRQUZ3DzbbzMYxWJk2p8MOAd+HtJI4Fvg2ckpNchk9eu4AiF9prtp2PYbQyiZsOicgz\nwABwj6r+MFepUlCUpkONotrdwKJlj0SadHq6uxL7OgzDaF4ybzoEvF5jNIqIfEFVP1Q2djDwA+Ag\n/173qeoNIjIHuBt4LV6RwHer6qsichBwO3Ay8BJwiapuTSFj4cjTpFNNme5AFtcXac5hwzDCJA6B\njVMQPosixvYAi1V1HjAfOEtEFgKfBm5R1d8HdgAf8I//ALDDH7/FP65pyTveP02oaLksLsw5bBhG\nmDR5EqlRj9/5T0v+jwKLgfv88duAPv/xef5z/NdPF0lSmaj+VCrGB/nH+6cJFU1SZtycw4ZhlJOr\nkgAQkU4R2QC8CDwM/BwYUdW9/iHPAYFtpAfYBuC/vhPPJFV+zatEZFBEBrdvr3+NwaQ7hLzj/dMk\nycXdM0j8S5KYZxhGe5Glkohc8avquKrOB47Gi4Y6odYbqeqtqtqrqr0zZ86s9XKpSbpDyDvTOWnZ\n7YGhYTocG7Ke7q6aSowbhtHapMqTABCRaaq6K+Klz8edp6ojIvIo8MdAt4gc4O8WjgaCJfgwcAzw\nnIgcAEzHc2AXiqQ7hKzi/V3O7yShosGuZzzCpeSSpaj5E4Zh1J80IbB/glfU7zWqOktE5gH/XVX/\nKuacmcCYryC6gIfwnNFXAver6t0i8mXgJ6r6jyJyNTBXVT8oIpcC56vqxXFyNSIENk34aK0TblRf\n665SZ2LTkEvWThEuO/UYHn1i+yTZgCn3EzxHUo8pDMNoGZKGwKZREuuAC4GVqrrAH3tcVf8o5pw3\n4jmiO/FMW/eo6qdE5PV4IbCHA0PAFaq6xw+Z/SdgAfAycKmqPh0nVyOURK0TdxpqzWeY07/KGc3U\nVeqc8h4OLnVEljsPH2O+C8NofvLIk0BVt5UFG8WGy6jqT/Am/PLxp4nI1lbV3cBFaWRqBPXMCK7V\n+e2qg9QpEulXqRQBVfQ+FIZhZEsaJbHNNzmpiJSADwM/y0es4lOv7mq1Frtz+UUqKYM4LOHOMNqH\nNNFNHwSuxgtTHcZLjrs6D6GaGVf+RJK8iiiSRjC56FvQw83nz53U4+Lm8+fSVYr+6rtKHVPuV44l\n3BlG+5CmVPivgctzlKXpcZXJGPzFy9y/friqYnrB60tXbmZk1PMVHOyY4OOuUR7xNDq2L/LYg0ud\n3HDOiRMlygOndYAl3BlGe5F4thGRz4jIYSJSEpHvish2EbkiT+GKRqXdgCt/4q5122rOvN6zd/+k\nvmPXWE3lPeLuO7JrjL4FPazpX8zWZWdzyyXzp+xCzB9hGO1DGp/EGar6MRF5F7AVOB+veF9b9JNI\nUkzPZauPylGIO76cuOQ914QdF3obd99yU1K9fC+GYRSTNHaLQKGcDdyrqjtzkKewJMmydtnqOx3Z\nzklt+2kjnD45sIlrV2xwlg1x3VfATEmGYUwijZL4ZxF5Aq+M93f9RLnd+YhVPJJM1C4n82WnHlOT\n8zlNeY+BoWHuXPvslNyIsEKLklOAyxfOsl2DYRiTSOO47heRzwA7VXVcRF7Bq9raFiQJRa2UP/HN\ndc+yb2L2TpbECOnKeyxfvaVirwjr/ObGSpIYxmTStC99T+hx+KXbsxSoqCSZqF0TzMDQMCt+vC2k\nIGB0bB9L7t0IJI9wSjJ5JfU3mK9hKkVu6WoYjSKN4/pNoccHA6cDj9EmSqLSRB03wSxfvYWx8anr\n+7F9ytKVmxNN/kknddeOx/wNlakmQMAwWp3EtZumnCjSDdytqmdlK1I6itLjOq7GUly70HJqLaYX\nVVcqfN2gsN9NfXNTXbcdcNW5EuCZZWfXWxzDyJWktZtq6SfxCjCnhvNbijjHdve0UuLrBJNUta1O\nyzOsg8zq4Lrjqtyx9lk+ObAp1XXbgbz7fxhGM5Imme4BEVnp/6wCtgDfzk+05sI1kXRPK/G73Xsj\nX6tEta1Og2S4Z5adzat7o/cwd63bVpVMrUytJVAMoxVJ45P4bOjxXuAXqvpcxvI0LS7Htqrne6iW\nWovpuRL5XOPtjEV9GUWmUZF3aUJgvy8iR7Dfgf1kPiI1J64J5toVG2q6bq2mjk6RSIXgSvBrBvL8\nZ7GoL6OINDLyLk0I7MXAcuB7eL68L4jIElW9LyfZmo6oCSYolFeOa/IuZ8cre5jTvyr1ZBhMpK57\nXHbqMYmuUzQsTNVoRxoZeZemM91G4G2q+qL/fCbwb6o6L0f5KlKU6CYXri52F5zcM6kybBLCkU+n\nnTBzSuvRICfjxgc2O7vLNXt0kyuKrLurxIYbzmiARIaRP3lE3uXRma4jUBA+L1FbdFTLEGf+cJmh\nAP554/OplEQ48umOtc9OjLtKkpeTtOVpkXH5aEZGxxgYGrbdhNGS1Np8rBbSTPL/KiKrReS9IvJe\nYBXwYD5iNQ/BTiFcTO+aFRtY8KmHJsJX+xb0sOTM4znKz5m48YHNLLl340R/iCxwlSQP0wod5eL+\nKaqJBGtnqm2EZdSfRkbepXFcLxGRC4BF/tCtqtr2IbBRtkLY3/MhIGxycpmCaqWSj6MV4v2XnHk8\n1ziCAVpBCdYL8+00F42MvEtjbkJV7wfuz0mWpiRuYgrnOdTSUzopcc7wUoe0RLx/34Iep8+lFZRg\nvbASJM1HoyLv0iTTnS8iT4rIThH5jYj8VkR+k6dwzUCliemXI6NVr3BFYIafrV0pYDUoSe467jUH\nHzDxB/bJgU0ce92DzO5fxbHXPdh02dc3nHOiJb3VSNoeJUb7ksYn8RngXFWdrqqHqeqhqnpYXoI1\nC1G2wjBHdXdVtcItdQi3XDyfoevPiGwjesXCWVPait7UN9dZI2rEX3l/cmATd6x9dmLH0YxlOspL\nj1hb1fRYCRIjKWlCYNeo6qLKR9aXIoTADgwNs3Tl5imO6CBktburxG92j5Em8XrGtBJD11cO6SyP\nrHplz95Ih3gQ2XTsdQ86k+t+fvM7kguYAOvNUFxcodmmbNuHzEJgReR8/+GgiKwABoA9weuq+q2q\npWwRAlthMCkGoWrBVFxNFNOOXWMsWvZI7AQb5XyMImyKiSvT4QohrWayN8dosbESJEZSkjiuzwk9\n3gWEl7cKtL2SCPPKnuqK+UURTPquCdYVWQXukuNxzu2oe1Q72ZtjtPhYCRIjCRWVhKq+L8mFROQ6\nVb25dpEaTxYr56wpn2AHhoadOwfYryDKk+cuO/WYSYl4cfeA6if7rB2jZroyjMaQZcb0RRleq2FE\nJccl6esQt6rPimCCDWSsxPDI6BS5b+qbyxULZ1W8h+t5pfGALB2j1X4nhmHUTpZKonnLioaIWznH\nUY/QwaB5URqFFEym4ezaR5/YPhFaW075JF7tZJ9lhmi134lhGLWTpZJoiQYFrsl+eGQ0tnxBPUIH\nf7d7LwNDw6kU0ujYODc+sHnKSvx3u/dS6pys16Mm8Won+yzDVC2m3zAaR6qM6wpM2UmIyDHA7cAR\neErkVlX9vIgcDqwAZgNbgYtVdYeICPB54B14TvL3qupjGcpYEVchLWCSqQMmO25PO2Emd659doqm\nnDGtlFkZjrF9yvLVW2JljCLq/mP7lO6uEoccdECsnb+WKJisHKONLG5mGO1Olkri3oixvcBHVPUx\nETkUWC8iDwPvBb6rqstEpB/oBz4OvB04zv85FfiS/7tuRHWYKyfKiXz/+uFJCkKAyxfO4qa+uc7y\n1tXwy5FRLl84a4pC6uwQxlN2wNs5OpaovHajo2BcXf8sw9ow8idN06GZwF/grf4nzlPV9/u//6b8\nHFV9Hnjef/xbEfkZ0AOcB7zVP+w2vEZGH/fHb1cvw2+tiHSLyJH+depC+crZNe2GTR1RNnMFHn1i\nO8BEh7o0U3gQwlpO97TSFIUEpFYQEL8SL1I0kcX0G0bjSLOT+A7w78C/AanDeERkNrAAWAccEZr4\nf4VnjgJPgWwLnfacP1Y3JQGTV86uXUB4gq1kM+9b0OOsXApTcxeCpkLlvSGCntlZRFHFrcQbkQhX\nSSk1ejfTSIqksI32I43jepqqflxV71HV+4OfJCeKyGvwqsdeo6qTigL6u4ZUy2ARuUpEBkVkcPv2\n7WlOTU2U41bwfBABSSKAehzHCJOzoIPJ+6a+uZGO35019qBI4kSudzSRhbi6sc/GaDRplMQ/i0jq\n4j4iUsJTEHeGSni8ICJH+q8fCQQd74aBcPPlo/2xSajqraraq6q9M2fOLH85U/oW9HDByT2TvPIK\n3L9+eOIfNUkEkEvZlGvH8GTct6CHNf2LeWbZ2azpX0zfgp6anbVJVqL1jiayEFc39tkYjSaNkvgw\nnqIYTVoq3I9W+hrwM1X929BLK4Er/cdX4pmygvH3iMdCYGc9/RFRDAwNc9e6bRUn80rhnlHHJPF3\nlFOp6mwlkqxE610h1EJc3dhnYzSaNJ3pDq3i+ouAdwObRCQwyv8vYBlwj4h8APgFcLH/2oN44a9P\n4YXAJioJkhefHNgUGdYaEP5HTWIzLz8mib9jYGh4UpOd7q4SF5zc4yytkYRKZTXqHU2UNMS1HW3z\nFv5rNJpUIbAiMgMvPPXgYExVf+A6XlX/H+5M7NMjjlfg6jQy5cXA0HCsgoDqo4PC1WLLTU5hf8fA\n0DAfuXfjpMilkdExvrnuWUQgYZX3SOJWovWOJkqilNq1qqyF/xqNJk0I7H/DMzkdDWwAFgI/BBbH\nndesLF+9JVZBVBsdBJP7XZffQ4E71z7LHWufpUOI7EFRRbTrFCqtRKuJJqp2pZ9EKbVrVVkL/zUa\nTZqdxIeBNwFrVfU0ETkBmJIb0SrErbQ7RWqKDqoUwhrogCyUQalTQL0M64A8VqK1rvQrKaV2ts23\nc/iv0XjSOK53q+puABE5SFWfAFp2z+taaQvwuYvnxf7TurKrh2vod10NM6aVWH7hPJZfNC9RDaVw\nEUBXjSoXeUfhWLtNw2gMaXYSz4lIN15nuodFZAee07klibIFB6U2Kq3qXI19OkX4r9MPzqxERxzl\n7U/z7iSX90rfbPOG0RjSRDe9y3+4VEQeBaYD/5qLVAUgrS04bI93WYnGVRPVhsqCkV1jk2Sa3lVC\nxBvPw+afdxSO2eYNozEk6XF9mKr+xq/cGhB4YV8DvJyLZAUgqS04aVe6nu6uyMnutBNm8ugT2yOj\nnTr8KKa07onuaaVJMoX7bEftEmrdCdRjpW+2ecOoP0l2Et8E3gmsx5urypOPX5+DXIWmPIrnlT17\nKyqIDmDXq3uZ078qdhVcvvp/5dW9jI2n92BXKk9evkuodSdgK33DaE1Eawm2LwC9vb06ODhYt/tl\n3cu6u6vE0nNPjJxMXcl2rgqxaRHglkvmO3M2ukqdVTcKMgyj2IjIelXtrXRcEnPTSXGv17spUKPJ\nupf1yOgYS+7dCEx1ELtMPYrbOZ6G6V2lKTkbgaLoqXEnkEV2dC3XaMfsbMPIgyQhsJ/zf76IV+b7\nVuAr/uMv5idaMckjhDXoOFeOy9TT093F5y6eV1MNp65SJyJTczYUb3cDcO2KDalDYSGbyqW1XMMq\npxpGdlRUEqp6mqqehtfT4SS/+urJeL0h2u6/zjVxz5hWcpYDT0KUWSmuumy4YGASurtKzJhWmpQr\nMeLwW4yMjtU0wWaRM1HLNaxyqmFkR5o8ieNVdaK2hKo+LiJ/mINMhcYVxXPDOZ5fYWBomCX3bUzt\nbBa8FXB55VhwO4ODaJ84P0mcXyHwRVQibfmLLHImarlGO2dnG0bWpFESPxGRrwJ3+M8vB36SvUjF\nxhXCunz1Fq5dsYGjuru45E3HTIS0JkWBpSs3RyqEJNVlA5mGR0Yn/BWV/AppcjbSTLBZ5EzUcg2r\nnGoY2ZE4uklEDgb+EniLP/QD4EtBqY5GkWd0UxLnZ9QqvqvUyQUn90xpP5qWUqew/MLJJUCydsiW\nX2/Xq3sjw2c7RSqWIwlfM+ozSRMpVcs1sri/YbQ6SaObUoXAikgXMEtVC2PczUtJJJ1oXGGqWUQf\nweTyGi6zUlwYbXBemsxx1+6i1CEsvyi5orDopmxopfdiFIfMlYSInAssBw5U1TkiMh/4lKqeW5uo\ntZGXkph/40OTspQDerq7WNO/vzr6nP5VmeQsxLF12dmAWyGBe6Vczap6YGiYa1dsiHxf3V0lNtxw\nRsQrRh7YrsjIi6RKIk0V2BuAU4ARAFXdAMypTrxiMzA0HKkgYKptvp527ji/QFT0zsDQMB+5Z2Oq\nSJ9g1epSfK7PJXx+tZVkG3HdomORWkajSeO4HlPVnV7b6gmaO13bQdw/YFepg0XLHpnY+s9+bVds\nUb9aCXIWwO2QDQgrkWAF6jJ5RSmcWrPJ8+oe165d6aAYkVpm7mpv0uwkNovInwOdInKciHwB+I+c\n5Goocf+Au8b2TcohWPPzl6vZTEIWAAATtUlEQVRWEMf9l0Modbi6u3o+gKXnnjjxPGhr6uKo7q6J\nFfc1KzbETvZRO6Ak2eQzppWcr9W66nXtFtp5Nd3oPhqWmGikURIfAk4E9uAV/duJ162u5ajXP+Cu\nV/ex/KJ5k3YLwUatp7tripP40Se2x15vZNerLLl3Y8XQW1d11kqr01KncMM5Jzpfj1v1VjIXxU1G\n1a6mW8FEFZdQWQ/aWUEbHmnMTW/wfw7wf84DzgXemINcDaVePR+GR0YnciviopMCKk2Kr7xaWd5O\nES44uWdSXkdgPogzZ82YVppIGHThOr+8RlSUuShuMqom76FVTFSNrq5bBHOX0VjSKIk7gY8CjwP7\n8hGnGAT/gB+5Z2MmYaxxhFfN4XtHUcknUYmo/I3hkVGW3LeRpSs3MzI65qwwu3us8lfuykaPqhFV\nnsUdNxndcsn81L0qam2iVCQa2UfDEhONNOam7ar6gKo+o6q/CH5yk6zB9C3o4XMXz0v1AdVCki38\nkjOPx+3BiCeo1/ToE9unTJ5j4zoRteRSiUnkC9eTSlIjKqwY4mzvruvGTZy2As6GRpu7jMaTZidx\ng1+W47t4fgkAVPVbmUvVQMKRHAeXOipumTqA6dNK7Ng1dRWetu9DYLuPq9V0zYoNqd5POKZ+YGi4\npp1Ikgk2atXrqhEVVgyVOtulXU3bCjgbGm3uMhpPGiXxPuAEoMR+c5MCLaMkyu3YowlMLPuAaQce\nwND1Z0yZ4NNOyOUtR6PMUD0VrlvqFA458AB2jk7uZR28t1qodoJN0to068moHu1U2wVrG9vepMm4\n3qKqhfsPyzLjOi6jOQ4BnvGzomH/biTNtbpKnRx0QEfFLO+BoeHY3cQVC2dxU9/cKePVvrewfEmz\nfKN2Q1D/1ajF9xuGm8w604X4DxF5g6r+tAa5Ck219upghT0wNMyND2yu2F86ipvPn8u1jsm/XK7O\nDmF8X7Ryd4XJ1mKL7xRJpSDKd0NBiY+e7i5uuWR+3SZqWwEbRu2kURILgQ0i8gyeT0IAVdWWCYGt\nxkQUmDBqyVbu8Z2zrt1Hhwhz+ldNVGl1KQhwKwPXe0viN9mnmniyjYoqCq7frGGohtHOpAneOQs4\nDjgDOAd4p/+7ZYiK5OgAgqToThEWHXt4ZJRNtb2vw3byqPsDjKtOhMpW2qW4/AZR1w4URKefwdcp\n0bFTaXwRlXYslohlGM1F4p1EK4e7BpQ7T7unlVCFnaNjFRv4VJocu7tKHHLQAbFNgcrv35Gy3Hic\nY7a8MVF4BzGu6uyBkdbZm2Q3ZmGohtE8pDE3tQWulqCVTCVxk2NXqTNRRnU56RRER0W/QfDeopzY\no2PjPPrEdm4+f+4UJXntig0sX70lkeM3SbZ60p2JOZ4No/HkmismIl8XkRdF5PHQ2OEi8rCIPOn/\nnuGPi4j8vYg8JSI/EZGT8pStEmlr1rhMRd1dpcTd1Obf+BDXrNgwUb8oDYcfclAmPaj7FvSwpn8x\nt1wyn91j+xgZHUtV2C2c+AZMSf5LujOxwnKGUQzy3kl8A/gH4PbQWD/wXVVdJiL9/vOPA2/H83kc\nB5wKfMn/3RDSZuy64vyDsaBO0mknzOTRJ7ZPOabWWlFZ96CupaxFOKqo2t1AK5XVMIxmJlcloao/\nEJHZZcPnAW/1H98GfA9PSZwH3K5e4sZaEekWkSNV9fk8ZXQxvasUmbMQZyopD7mMMlndsfbZideD\n8NBSp/DqeG01olxyRU3SSRLNsiprUW0YqpXVKA5m9mtv6lWaKMwRoYn/V8AR/uMeYFvouOf8sSmI\nyFUiMigig9u3x5fProaBoWFeeXXvlPFSh6Ry4iaJeFKoWUG4TDgukw1QsRZSo/sYNPr+hoeZ/YxG\nKIkJ/F1D6hlSVW9V1V5V7Z05M74RTzUsX72FsYiJ+zUHH5BqBZXnqjdJsbtKJps1/Yt5ZtnZrOlf\nPOX8Rhd2a/T9DQ/rJ2E0IrrphcCMJCJHAi/648PAMaHjjvbH6o5rct+xa4xjr3uQy049ZlLpC9d2\nvNbS3i7CZTriqMVk0+jCbo2+v+FhZj+jEUpiJXAlsMz//Z3Q+F+LyN14DuudjfJHxE3u46oTfoWb\n+ubGhsrW2rxoxrQSv9u9l7FQhnWa1XStlVDrWdbCpWhNKTSWLKrpmk+juck7BPYu4IfA8SLynIh8\nAE85vE1EngT+zH8O8CDwNPAU8BXgr/KULQ5XOGuYu9Z57pNKJp2w7d+V0VxOV6mTv7tkPkPXn8Hy\ni+al6qNQ6X0U0WRjdu/iUuvfkH23zU/e0U2XOV46PeJYBa7OU56kBJNw0K0tiiDRrVJf56SlwztF\n2Kca2UOi2lVXs5hsLNy1uNT6N2TfbfOTuFR4UcmyVHg5ceW1ReCo6e6Jv7urxJ69+1KZmraGyo23\nE3P6V0VGL5SXYDeaD/tui0sepcLbjjjnnEBsGY6ovs5xhE1R9ejHUCQ7sXWRa13su21+GhoCW3Ti\n/pBd1bor9XV2EZivomy4S+7dyJL7NmZm1y2anbhZfCdGeuy7bX5MScQQ9Qde6nQ7nwUmQlM7Ejqp\nA4JaR1E23LF9OiVvo5ZY9axj3weGhlnwqYeY3b+K2f2rmH/jQ6kUTrmDP62D3igu9t02P2ZuonL4\nZfi1V/bsdTqzO0SY3b8qUSOfMOGVVZq8Cpc5rJIpKcvY94GhYZbct3GSEhsZHWPJvRuB5M2FLNy1\ndbHvtrlp+51EWtOLS0HAfpNRGgXRKTKxih8YGk4cJgv7O9YtWvbIhLxJ3k+WJS9c2elj+9Sycg2j\nBWh7JRFneomacNMZkeIR9iuWYDJP00Mi3LEuUARJTElZ2onjdh+WlWsYzU/bm5viTC+ufs1pzUku\nyq8xOjY+0bUuLYEiSGJKiot9Txv1FJf/YREshtH8tL2SiAvRc024iueACybSXa/urdh7OinjqlOU\nUFKlFJe0Vz5hR9mJ03bjA29XUu6TgPQVcw3DKCZtb26KM724VsJBgb2gguoN55w45RoSOvaKhbOc\nr0ehTD4/6b4iWPlXa0qqJuqpb0EPyy+cx4xppYmx7q4Syy+aZ85Kw2gB2n4nUansQKXmPEmuEXDX\num2TnNtxO4Rg/Fc7dyd6H4FctZRRqDbqyaJXDKN1aXslAe5JLs2EW35ssPoO7Pz3rx+e4mtIskNw\n+SdKncIhBx7AztGxzOo9WXasYRjltL2SqOSoTTrhxtnzk3SoS0NPTmU0krQ1NQyjvWhrJVGNo9ZF\nnD0/y1DQcFZ31jRL1VjDMOpHWyuJLMsYx9nzk3ao60lwXN6mH/MvGIYRpq2jm7IsT+GavDtEEifh\nrelfzN9dMt/Z8MhMP4Zh1Ju2VhJZlqdwdbMrj2Zy0d3lhZCGC6LB/hLiVhjNMIxG0NbmpiwdteX2\n/I6IzGnFUwav7Jnct7rUISw998RJ1zJlYBhGEWjrnUTWZYz7FvRMJNm5Qld3jo5N6VttiWeGYRSV\ntt5JQD6r9oGhYWei3FHdXbZTMAyjaWjrnUReLF+9xdnX1xzPhmE0E6YkciCuMKDtIAzDaCZMSeRA\nXGFAwzCMZsKURA5Y83fDMFqFtndc54GVtzAMo1UwJZGSpJ3bLILJMIxWwJRECrIsCGgYhtEMmE8i\nBdV0bjMMw2hmTEmkIMuCgIZhGM2AKYkUZFkQ0DAMoxkonJIQkbNEZIuIPCUi/Y2WJ4yFthqG0W4U\nynEtIp3AF4G3Ac8BPxaRlar608ZK5mGhrYZhtBuFUhLAKcBTqvo0gIjcDZwHFEJJgIW2GkZuhCsn\nux5X+1rWxzXyXoceCl31M3EXTUn0ANtCz58DTs39rp/9LDz4oPe4KH8Idq/WkKlV75WFTEZ1fOMb\ncOWVdbtd0ZREIkTkKuAqgFmzZtV+wfFx2Ls3fIPyG+7/HX7NdVzc42pfs3s1r0yteq8iytQO9zo1\n/3XzpNtqgTS7iPwxsFRVz/SfXwegqje7zunt7dXBwcE6SWgYhtEaiMh6Ve2tdFzRopt+DBwnInNE\n5EDgUmBlg2UyDMNoWwplblLVvSLy18BqoBP4uqpubrBYhmEYbUuhlASAqj4IPNhoOQzDMIzimZsM\nwzCMAmFKwjAMw3BiSsIwDMNwYkrCMAzDcGJKwjAMw3BSqGS6ahCR7cAvarjE64BfZyRO3pis+WCy\n5oPJmg9Zyfp7qjqz0kFNryRqRUQGk2QdFgGTNR9M1nwwWfOh3rKauckwDMNwYkrCMAzDcGJKAm5t\ntAApMFnzwWTNB5M1H+oqa9v7JAzDMAw3tpMwDMMwnLS1khCRs0Rki4g8JSL9DZLhGBF5VER+KiKb\nReTD/vhSERkWkQ3+zztC51zny7xFRM6s5/sRka0issmXadAfO1xEHhaRJ/3fM/xxEZG/9+X5iYic\nFLrOlf7xT4pI5m22ROT40Ge3QUR+IyLXFOVzFZGvi8iLIvJ4aCyzz1FETva/p6f8c8s62NQs63IR\necKX59si0u2PzxaR0dDn++VKMrned4ayZvadi9fGYJ0/vkK8lgZZyroiJOdWEdngjzfuc1XVtvzB\nK0X+c+D1wIHARuANDZDjSOAk//GhwH8CbwCWAh+NOP4NvqwHAXP899BZr/cDbAVeVzb2GaDff9wP\nfNp//A7gXwABFgLr/PHDgaf93zP8xzNy/q5/BfxeUT5X4C3AScDjeXyOwI/8Y8U/9+0Zy3oGcID/\n+NMhWWeHjyu7TqRMrvedoayZfefAPcCl/uMvA3+Zpaxlr38OuL7Rn2s77yROAZ5S1adV9VXgbuC8\neguhqs+r6mP+498CP8Pr9e3iPOBuVd2jqs8AT+G9l0a+n/OA2/zHtwF9ofHb1WMt0C0iRwJnAg+r\n6suqugN4GDgrR/lOB36uqnFJl3X9XFX1B8DLETLU/Dn6rx2mqmvVmyFuD10rE1lV9SFVDXr+rgWO\njrtGBZlc7zsTWWNI9Z37K/TFwH15y+rf62Lgrrhr1ONzbWcl0QNsCz1/jvjJOXdEZDawAFjnD/21\nv53/emir6JK7Xu9HgYdEZL14vcYBjlDV5/3HvwKOKIisAZcy+Z+tiJ8rZPc59viPy8fz4v14K9iA\nOSIyJCLfF5E/9cfiZHK97yzJ4jt/LTASUo55fq5/Crygqk+GxhryubazkigUIvIa4H7gGlX9DfAl\n4FhgPvA83tazCLxZVU8C3g5cLSJvCb/or2YKEzLn24zPBe71h4r6uU6iaJ+jCxH5BLAXuNMfeh6Y\npaoLgP8JfFNEDkt6vZzed1N852VcxuSFTcM+13ZWEsPAMaHnR/tjdUdESngK4k5V/RaAqr6gquOq\nug/4Ct4WGNxy1+X9qOqw//tF4Nu+XC/4295g+/tiEWT1eTvwmKq+4MtdyM/VJ6vPcZjJ5p9cZBaR\n9wLvBC73JyF8081L/uP1eLb9P6ggk+t9Z0KG3/lLeKa+A8rGM8W//vnAitB7aNjn2s5K4sfAcX60\nwoF4JomV9RbCtz1+DfiZqv5taPzI0GHvAoIIiJXApSJykIjMAY7Dc1zl/n5E5BAROTR4jOe8fNy/\nTxBZcyXwnZCs7xGPhcBOf/u7GjhDRGb4W/8z/LE8mLQiK+LnGiKTz9F/7TcistD/+3pP6FqZICJn\nAR8DzlXVXaHxmSLS6T9+Pd7n+HQFmVzvOytZM/nOfUX4KHBhXrL6/BnwhKpOmJEa+rlW4+1ulR+8\nqJH/xNPKn2iQDG/G2wb+BNjg/7wD+Cdgkz++EjgydM4nfJm3EIpayfv94EV7bPR/Ngf3wLPVfhd4\nEvg34HB/XIAv+vJsAnpD13o/nqPwKeB9OX22h+Ct/qaHxgrxueIprueBMTw78gey/ByBXrzJ8OfA\nP+AnzmYo61N4dvvgb/bL/rEX+H8bG4DHgHMqyeR63xnKmtl37v8P/Mh///cCB2Upqz/+DeCDZcc2\n7HO1jGvDMAzDSTubmwzDMIwKmJIwDMMwnJiSMAzDMJyYkjAMwzCcmJIwDMMwnJiSMAzDMJyYkjDa\nAhHpFpG/qnDMbBH58wTXmi2h8s6G0cqYkjDahW4gVknglWOuqCTSECrhYBhNiSkJo11YBhzrN2xZ\n7v887jdruSR0zJ/6x1zr7xj+XUQe83/+JMmNROS9IrJSRB4BvuuX05hyv5jxt/qVPr8jIk+LyDIR\nuVxEfuQfd6x/3EX+uRtF5AfZf2SGAbbKMdqFfuCPVHW+iFwAfBCYB7wO+LE/yfbjNad5J4CITAPe\npqq7ReQ4vDIKvQnvdxLwRlV92b/f/Ij7/YljHH/sD/H6DTwNfFVVTxGvc+GHgGuA64EzVXVY/M5w\nhpE1tpMw2pE3A3epVxn0BeD7wJsijisBXxGRTXh1et6Q4h4Pq2rQUMZ1vzg5fqxeQ6o9eDV5HvLH\nN+GZxQDWAN8Qkb/A66ZmGJljOwnDcHMt8ALeqr4D2J3i3FdqvPee0ON9oef78P9vVfWDInIqcDaw\nXkROVr+ctGFkhe0kjHbht3g9xAH+HbhERDpFZCZer+EflR0DMB14Xr0+BO+m+tW6636u8USIyLGq\nuk5Vrwe2M7kHgmFkgu0kjLZAVV8SkTV+6Oq/4JWN3ohXpv1jqvorEXkJGBeRjXjlmv8RuF9E3gP8\nK9XvDr4N/HHE/VzjJyS87nLfVyJ4JaE3VimfYTixUuGGYRiGEzM3GYZhGE7M3GQYVSIiZwKfLht+\nRlXf1Qh5DCMPzNxkGIZhODFzk2EYhuHElIRhGIbhxJSEYRiG4cSUhGEYhuHElIRhGIbh5P8D4Ruv\n/wWfVqMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0lRt4USU81L",
        "colab_type": "text"
      },
      "source": [
        " 这条初始线看起来与目标相差很大。看看您能否回想起摘要统计信息，并看到其中蕴含的相同信息。\n",
        "\n",
        "综上所述，这些初始健全性检查提示我们也许可以找到更好的线。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZWF67uv0HTG",
        "colab_type": "text"
      },
      "source": [
        " ## 调整模型超参数\n",
        "对于本练习，为方便起见，我们已将上述所有代码放入一个函数中。您可以使用不同的参数调用该函数，以了解相应效果。\n",
        "\n",
        "我们会在 10 个等分的时间段内使用此函数，以便观察模型在每个时间段的改善情况。\n",
        "\n",
        "对于每个时间段，我们都会计算训练损失并绘制相应图表。这可以帮助您判断模型收敛的时间，或者模型是否需要更多迭代。\n",
        "\n",
        "此外，我们还会绘制模型随着时间的推移学习的特征权重和偏差项值的曲线图。您还可以通过这种方式查看模型的收敛效果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgSMeD5UU81N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(learning_rate, steps, batch_size, input_feature=\"total_rooms\"):\n",
        "  \"\"\"Trains a linear regression model of one feature.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    input_feature: A `string` specifying a column from `california_housing_dataframe`\n",
        "      to use as input feature.\n",
        "  \"\"\"\n",
        "  \n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "\n",
        "  my_feature = input_feature\n",
        "  my_feature_data = california_housing_dataframe[[my_feature]]\n",
        "  my_label = \"median_house_value\"\n",
        "  targets = california_housing_dataframe[my_label]\n",
        "\n",
        "  # Create feature columns.\n",
        "  feature_columns = [tf.feature_column.numeric_column(my_feature)]\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda:my_input_fn(my_feature_data, targets, batch_size=batch_size)\n",
        "  prediction_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n",
        "  \n",
        "  # Create a linear regressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  linear_regressor = tf.estimator.LinearRegressor(\n",
        "      feature_columns=feature_columns,\n",
        "      optimizer=my_optimizer\n",
        "  )\n",
        "\n",
        "  # Set up to plot the state of our model's line each period.\n",
        "  plt.figure(figsize=(15, 6))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title(\"Learned Line by Period\")\n",
        "  plt.ylabel(my_label)\n",
        "  plt.xlabel(my_feature)\n",
        "  sample = california_housing_dataframe.sample(n=300)\n",
        "  plt.scatter(sample[my_feature], sample[my_label])\n",
        "  colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  root_mean_squared_errors = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    linear_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.\n",
        "    predictions = linear_regressor.predict(input_fn=prediction_input_fn)\n",
        "    predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "    \n",
        "    # Compute loss.\n",
        "    root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(predictions, targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    root_mean_squared_errors.append(root_mean_squared_error)\n",
        "    # Finally, track the weights and biases over time.\n",
        "    # Apply some math to ensure that the data and line are plotted neatly.\n",
        "    y_extents = np.array([0, sample[my_label].max()])\n",
        "    \n",
        "    weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]\n",
        "    bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
        "\n",
        "    x_extents = (y_extents - bias) / weight\n",
        "    x_extents = np.maximum(np.minimum(x_extents,\n",
        "                                      sample[my_feature].max()),\n",
        "                           sample[my_feature].min())\n",
        "    y_extents = weight * x_extents + bias\n",
        "    plt.plot(x_extents, y_extents, color=colors[period]) \n",
        "  print(\"Model training finished.\")\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.xlabel('Periods')\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(root_mean_squared_errors)\n",
        "\n",
        "  # Output a table with calibration data.\n",
        "  calibration_data = pd.DataFrame()\n",
        "  calibration_data[\"predictions\"] = pd.Series(predictions)\n",
        "  calibration_data[\"targets\"] = pd.Series(targets)\n",
        "  display.display(calibration_data.describe())\n",
        "\n",
        "  print(\"Final RMSE (on training data): %0.2f\" % root_mean_squared_error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg8A4ArBU81Q",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 1：使 RMSE 不超过 180\n",
        "\n",
        "调整模型超参数，以降低损失和更符合目标分布。\n",
        "约 5 分钟后，如果您无法让 RMSE 低于 180，请查看解决方案，了解可能的组合。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzoZUSdLIolF",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3685
        },
        "outputId": "3459992a-dec6-47a8-f0b8-9c1829535f0c"
      },
      "source": [
        "train_model(\n",
        "    learning_rate=0.00001,\n",
        "    steps=100,\n",
        "    batch_size=1\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "  period 00 : 236.32\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "  period 01 : 235.11\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "  period 02 : 233.90\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "  period 03 : 232.70\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "  period 04 : 231.50\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n",
            "       total_rooms\n",
            "12824       3244.0\n",
            "2956        2024.0\n",
            "3141        3550.0\n",
            "15694         44.0\n",
            "5754         151.0\n",
            "...            ...\n",
            "3729        1221.0\n",
            "14502       1210.0\n",
            "14809       2375.0\n",
            "5439        2231.0\n",
            "2249        2228.0\n",
            "\n",
            "[17000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-a555d2465b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-36-08b005cc5bf7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(learning_rate, steps, batch_size, input_feature)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Take a break and compute predictions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Compute loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    627\u001b[0m             hooks=all_hooks) as mon_sess:\n\u001b[1;32m    628\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m             \u001b[0mpreds_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myield_single_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m               \u001b[0;32myield\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAGECAYAAACiW/4hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajVM7rkoYXeL",
        "colab_type": "text"
      },
      "source": [
        " ### 解决方案\n",
        "\n",
        "点击下方即可查看一种可能的解决方案。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3zmldDwYy5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(\n",
        "    learning_rate=0.00002,\n",
        "    steps=500,\n",
        "    batch_size=5\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8H0_D4vYa49",
        "colab_type": "text"
      },
      "source": [
        " 这只是一种可能的配置；也许还有同样能够提供理想结果的其他设置组合。请注意，总体而言，本练习重点不是查找*一种最佳*设置，而是帮助您对模型配置调整如何影响预测质量有一个直观的认识。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU5sLyYTqzqL",
        "colab_type": "text"
      },
      "source": [
        " ### 有适用于模型调整的标准启发法吗？\n",
        "\n",
        "这是一个常见的问题。简短的答案是，不同超参数的效果取决于数据。因此，不存在必须遵循的规则，您需要对自己的数据进行测试。\n",
        "\n",
        "即便如此，我们仍在下面列出了几条可为您提供指导的经验法则：\n",
        "\n",
        " * 训练误差应该稳步减小，刚开始是急剧减小，最终应随着训练收敛达到平稳状态。\n",
        " * 如果训练尚未收敛，尝试运行更长的时间。\n",
        " * 如果训练误差减小速度过慢，则提高学习速率也许有助于加快其减小速度。\n",
        "   * 但有时如果学习速率过高，训练误差的减小速度反而会变慢。\n",
        " * 如果训练误差变化很大，尝试降低学习速率。\n",
        "   * 较低的学习速率和较大的步数/较大的批量大小通常是不错的组合。\n",
        " * 批量大小过小也会导致不稳定情况。不妨先尝试 100 或 1000 等较大的值，然后逐渐减小值的大小，直到出现性能降低的情况。\n",
        "\n",
        "重申一下，切勿严格遵循这些经验法则，因为效果取决于数据。请始终进行试验和验证。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpV-uF_cBCBU",
        "colab_type": "text"
      },
      "source": [
        " ## 任务 2：尝试其他特征\n",
        "\n",
        "使用 `population` 特征替换 `total_rooms` 特征，看看能否取得更好的效果。\n",
        "\n",
        "这部分不必超过 5 分钟。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMyOxzb0ZlAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci1ISxxrZ7v0",
        "colab_type": "text"
      },
      "source": [
        " ### 解决方案\n",
        "\n",
        "点击下方即可查看一种可能的解决方案。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjdQQCduZ7BV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(\n",
        "    learning_rate=0.00002,\n",
        "    steps=1000,\n",
        "    batch_size=5,\n",
        "    input_feature=\"population\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}